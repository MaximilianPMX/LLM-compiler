from src.llm_api.llm_api import LLM

class Chain:
    def __init__(self, prompt: str, llm: LLM):
        """Initializes the Chain with a prompt and an LLM.

        Args:
            prompt (str): The prompt to be used by the chain.
            llm (LLM): The language model to use for execution.
        """
        if not isinstance(prompt, str):
            raise TypeError("Prompt must be a string.")
        if not isinstance(llm, LLM):
            raise TypeError("llm must be an instance of LLM.")

        self.prompt = prompt
        self.llm = llm

    def execute(self, input_text: str = "") -> str:
        """Executes the chain using the LLM and returns the output.

        Args:
            input_text (str, optional): Input text to the prompt. Defaults to "".

        Returns:
            str: The output generated by the LLM.
        """
        try:
            final_prompt = self.prompt.format(input=input_text) # allow input variables in the prompt such as {input}
            output = self.llm.generate_text(final_prompt)
            return output
        except Exception as e:
            print(f"Error executing chain: {e}")
            return ""
